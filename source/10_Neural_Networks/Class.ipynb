{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today:\n",
    "* Neural Networks\n",
    "    * Neuron \n",
    "    * Arhitecture\n",
    "    * Activation functions\n",
    "    * Cost function\n",
    "    * Feed-forward\n",
    "    * Backpropagation\n",
    "  \n",
    "### Resources:\n",
    "* http://neuralnetworksanddeeplearning.com/\n",
    "* http://karpathy.github.io/neuralnets/\n",
    "* http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
    "* https://www.jessicayung.com/explaining-tensorflow-code-for-a-multilayer-perceptron/\n",
    "* http://adventuresinmachinelearning.com/python-tensorflow-tutorial/\n",
    "* https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/05_kNN/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../data/05_kNN/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../data/05_kNN/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../data/05_kNN/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data to the folder data/mnist\n",
    "mnist = input_data.read_data_sets(\"../../data/05_kNN/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f454691dba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45450b1cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = mnist.train.images[10].reshape((28, 28))\n",
    "plt.imshow(image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "n_input = 784    # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10   # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1':  tf.Variable(tf.random_normal([n_input,    n_hidden_1])),\n",
    "    'h2':  tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes ]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':  tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':  tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden fully connected layer with 256 neurons\n",
    "layer_1 = tf.add(tf.matmul(X, weights['h1']), biases['b1'])\n",
    "\n",
    "# Hidden fully connected layer with 256 neurons\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "\n",
    "# Output fully connected layer with a neuron for each class\n",
    "hypothesis = tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-24aceab9a66d>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, cost: 252.2769311940\n",
      "Epoch: 0002, cost: 98.8307684708\n",
      "Epoch: 0003, cost: 74.7608049237\n",
      "Epoch: 0004, cost: 61.0566481850\n",
      "Epoch: 0005, cost: 52.5266070483\n",
      "Epoch: 0006, cost: 45.9206814931\n",
      "Epoch: 0007, cost: 41.3196097877\n",
      "Epoch: 0008, cost: 37.8571086251\n",
      "Epoch: 0009, cost: 34.3896262854\n",
      "Epoch: 0010, cost: 32.0588042649\n",
      "Epoch: 0011, cost: 29.6977715735\n",
      "Epoch: 0012, cost: 28.0953365499\n",
      "Epoch: 0013, cost: 26.3657097996\n",
      "Epoch: 0014, cost: 25.0045427656\n",
      "Epoch: 0015, cost: 23.7405572393\n",
      "Accuracy: 0.8774\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "pred = tf.nn.softmax(hypothesis)\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0.0\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch: %04d, cost: %4.10f' % (epoch + 1, avg_cost))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
